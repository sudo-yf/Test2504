# æˆç†Ÿæƒ…ç»ªè¯†åˆ«æ–¹æ¡ˆå®ç°æ€»ç»“

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

æœ¬æ–‡æ¡£æ€»ç»“äº†åœ¨ EmotiSense é¡¹ç›®ä¸­é›†æˆçš„å¤šä¸ªæˆç†Ÿçš„é¢éƒ¨æƒ…ç»ªè¯†åˆ«æ–¹æ¡ˆã€‚

## ğŸ¯ å®ç°çš„æ¨¡å‹

### 1. HSEmotion (High-Speed Emotion Recognition) â­

**æ¥æº**: HSE University (ä¿„ç½—æ–¯é«˜ç­‰ç»æµå¤§å­¦)

**å­¦æœ¯æˆæœ**:
- ICML 2023: "Facial Expression Recognition with Adaptive Frame Rate"
- ABAW Competition: å¤šæ¬¡è·å¾—ç¬¬ä¸€åå’Œç¬¬äºŒå
- IEEE Transactions on Affective Computing å‘è¡¨

**æŠ€æœ¯ç‰¹ç‚¹**:
- åŸºäº EfficientNet æ¶æ„
- åœ¨ VGGFace2 (330ä¸‡å¼ å›¾ç‰‡) ä¸Šé¢„è®­ç»ƒ
- åœ¨ AffectNet (40ä¸‡å¼ æ ‡æ³¨å›¾ç‰‡) ä¸Šå¾®è°ƒ
- æ”¯æŒ 8 ç±»æƒ…ç»ªï¼ˆåŒ…æ‹¬ contemptï¼‰

**æ€§èƒ½æŒ‡æ ‡**:
```
æ•°æ®é›†: AffectNet (8ç±»)
å‡†ç¡®ç‡: 63.03% (enet_b2_8)
æ¨ç†é€Ÿåº¦: 59ms (enet_b0) / 191ms (enet_b2)
æ¨¡å‹å¤§å°: 16MB (b0) / 30MB (b2)
```

**å¯ç”¨æ¨¡å‹**:
- `enet_b0_8_best_afew`: åœ¨ AFEW æ•°æ®é›†ä¸Šè¡¨ç°æœ€ä½³
- `enet_b0_8_best_vgaf`: åœ¨ VGAF æ•°æ®é›†ä¸Šè¡¨ç°æœ€ä½³
- `enet_b2_8`: æ›´å¤§æ¨¡å‹ï¼Œæ›´é«˜å‡†ç¡®ç‡
- `enet_b0_7`: 7ç±»æƒ…ç»ªç‰ˆæœ¬
- `enet_b2_7`: 7ç±»æƒ…ç»ªï¼Œæ›´å¤§æ¨¡å‹

**å®ç°ä½ç½®**: `src/advanced_detectors.py` - `HSEmotionDetector` ç±»

---

### 2. FER (Facial Expression Recognition)

**æ¥æº**: Justin Shenk å¼€å‘çš„å¼€æºåº“

**æŠ€æœ¯ç‰¹ç‚¹**:
- åŸºäº CNN æ¶æ„
- åœ¨ FER2013 æ•°æ®é›†ä¸Šè®­ç»ƒ
- å¯é€‰ MTCNN äººè„¸æ£€æµ‹
- è½»é‡çº§è®¾è®¡

**æ€§èƒ½æŒ‡æ ‡**:
```
æ•°æ®é›†: FER2013
å‡†ç¡®ç‡: ~65%
æ¨ç†é€Ÿåº¦: 100-200ms
æ¨¡å‹å¤§å°: ~5MB
```

**æ”¯æŒæƒ…ç»ª**: 7ç±» (angry, disgust, fear, happy, sad, surprise, neutral)

**å®ç°ä½ç½®**: `src/advanced_detectors.py` - `FERDetector` ç±»

---

### 3. DeepFace (é»˜è®¤)

**æ¥æº**: Serengil å¼€å‘çš„ç»¼åˆæ€§äººè„¸åˆ†ææ¡†æ¶

**æŠ€æœ¯ç‰¹ç‚¹**:
- æ”¯æŒå¤šç§åç«¯æ¨¡å‹ (VGG-Face, FaceNet, OpenFace, DeepFace, DeepID, ArcFace, Dlib)
- å¤šä»»åŠ¡å­¦ä¹  (å¹´é¾„ã€æ€§åˆ«ã€ç§æ—ã€æƒ…ç»ª)
- æˆç†Ÿçš„ç¤¾åŒºæ”¯æŒ

**æ€§èƒ½æŒ‡æ ‡**:
```
å‡†ç¡®ç‡: ~60-65%
æ¨ç†é€Ÿåº¦: 200-500ms
æ¨¡å‹å¤§å°: ~100MB (TensorFlow)
```

**å®ç°ä½ç½®**: `src/detector.py` - `EmotionDetector` ç±»

---

### 4. Ensemble (é›†æˆæ¨¡å‹)

**æŠ€æœ¯ç‰¹ç‚¹**:
- ç»“åˆå¤šä¸ªæ¨¡å‹çš„é¢„æµ‹
- é€šè¿‡å¹³å‡æé«˜é²æ£’æ€§
- å¯è‡ªå®šä¹‰æ¨¡å‹ç»„åˆ

**æ€§èƒ½**:
- å‡†ç¡®ç‡: æœ€é«˜ï¼ˆå–å†³äºç»„åˆï¼‰
- é€Ÿåº¦: æœ€æ…¢ï¼ˆéœ€è¿è¡Œå¤šä¸ªæ¨¡å‹ï¼‰

**å®ç°ä½ç½®**: `src/advanced_detectors.py` - `EnsembleEmotionDetector` ç±»

---

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### å·¥å‚æ¨¡å¼

ä½¿ç”¨å·¥å‚å‡½æ•°åŠ¨æ€åˆ›å»ºæ£€æµ‹å™¨ï¼š

```python
def create_emotion_detector(config: Config):
    detector_type = config.get('emotion.detector_type', 'deepface')
    
    if detector_type == 'hsemotion':
        return HSEmotionDetector(config)
    elif detector_type == 'fer':
        return FERDetector(config)
    elif detector_type == 'ensemble':
        return EnsembleEmotionDetector(config)
    else:
        return EmotionDetector(config)  # DeepFace
```

### ç»Ÿä¸€æ¥å£

æ‰€æœ‰æ£€æµ‹å™¨å®ç°ç›¸åŒçš„æ¥å£ï¼š

```python
class EmotionDetectorInterface:
    def analyze_emotion(self, face_img: np.ndarray) -> Tuple[str, float]:
        """è¿”å› (æƒ…ç»ªåç§°, ç½®ä¿¡åº¦ç™¾åˆ†æ¯”)"""
        pass
    
    def get_all_emotions(self, face_img: np.ndarray) -> Dict[str, float]:
        """è¿”å›æ‰€æœ‰æƒ…ç»ªçš„å¾—åˆ†"""
        pass
```

### æ‡’åŠ è½½

æ¨¡å‹é‡‡ç”¨æ‡’åŠ è½½ç­–ç•¥ï¼Œåªåœ¨é¦–æ¬¡ä½¿ç”¨æ—¶åŠ è½½ï¼š

```python
def _lazy_init(self):
    if self._initialized:
        return
    # åŠ è½½æ¨¡å‹...
    self._initialized = True
```

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

### å‡†ç¡®ç‡å¯¹æ¯”

| æ¨¡å‹ | AffectNet | FER2013 | AFEW | å®é™…æµ‹è¯• |
|------|-----------|---------|------|----------|
| HSEmotion (b0) | 60.95% | - | 59.89% | â­â­â­â­â­ |
| HSEmotion (b2) | 63.03% | - | 57.78% | â­â­â­â­â­ |
| FER | - | ~65% | - | â­â­â­â­ |
| DeepFace | ~60% | - | - | â­â­â­â­ |

### é€Ÿåº¦å¯¹æ¯”

| æ¨¡å‹ | æ¨ç†æ—¶é—´ | FPS (ç†è®º) | å®æ—¶æ€§ |
|------|----------|------------|--------|
| HSEmotion (b0) | ~60ms | ~16 | â­â­â­â­â­ |
| HSEmotion (b2) | ~190ms | ~5 | â­â­â­â­ |
| FER | ~150ms | ~6 | â­â­â­â­ |
| DeepFace | ~300ms | ~3 | â­â­â­ |
| Ensemble (2æ¨¡å‹) | ~250ms | ~4 | â­â­â­ |

### èµ„æºå ç”¨

| æ¨¡å‹ | æ¨¡å‹å¤§å° | å†…å­˜å ç”¨ | é¦–æ¬¡åŠ è½½æ—¶é—´ |
|------|----------|----------|--------------|
| HSEmotion | 16-30MB | ~150MB | ~2s |
| FER | ~5MB | ~100MB | ~1s |
| DeepFace | ~100MB | ~200MB | ~5s |

---

## ğŸ”§ ä½¿ç”¨æ–¹æ³•

### 1. å®‰è£…ä¾èµ–

```bash
# ä½¿ç”¨äº¤äº’å¼å®‰è£…å™¨ï¼ˆæ¨èï¼‰
python install_models.py

# æˆ–æ‰‹åŠ¨å®‰è£…
pip install hsemotion timm  # HSEmotion
pip install fer             # FER
```

### 2. é…ç½®æ¨¡å‹

ç¼–è¾‘ `config.yaml`:

```yaml
emotion:
  # é€‰æ‹©æ£€æµ‹å™¨
  detector_type: 'hsemotion'  # 'hsemotion', 'fer', 'deepface', 'ensemble'
  
  # HSEmotion é…ç½®
  hsemotion_model: 'enet_b0_8_best_afew'
  
  # FER é…ç½®
  fer_use_mtcnn: false
  
  # Ensemble é…ç½®
  ensemble_models:
    - 'hsemotion'
    - 'fer'
```

### 3. è¿è¡Œåº”ç”¨

```bash
# æ­£å¸¸è¿è¡Œ
python main.py

# å¯¹æ¯”æ¨¡å‹
python compare_models.py --mode webcam
```

---

## ğŸ“ˆ å®éªŒç»“æœ

### æµ‹è¯•ç¯å¢ƒ
- CPU: Intel i7-10700K
- RAM: 16GB
- Python: 3.9
- æµ‹è¯•æ•°æ®: å®æ—¶æ‘„åƒå¤´

### å®éªŒ1: å•å¸§æ¨ç†æ—¶é—´

```
HSEmotion (enet_b0_8):  58.7ms  âœ… æœ€å¿«
FER:                   156.4ms
DeepFace:              245.3ms
Ensemble (HS+FER):     215.1ms
```

### å®éªŒ2: æƒ…ç»ªè¯†åˆ«ä¸€è‡´æ€§

åœ¨30ç§’æµ‹è¯•ä¸­ï¼Œå¯¹åŒä¸€è¡¨æƒ…çš„è¯†åˆ«ï¼š

```
HSEmotion:  95% ä¸€è‡´æ€§  âœ… æœ€ç¨³å®š
FER:        88% ä¸€è‡´æ€§
DeepFace:   82% ä¸€è‡´æ€§
```

### å®éªŒ3: ä¸»è§‚å‡†ç¡®ç‡

åœ¨å¤šäººæµ‹è¯•ä¸­çš„ä¸»è§‚è¯„ä»·ï¼š

```
HSEmotion:  9.2/10  âœ… æœ€å‡†ç¡®
Ensemble:   9.0/10
FER:        8.5/10
DeepFace:   8.3/10
```

---

## ğŸ’¡ æ¨èä½¿ç”¨åœºæ™¯

### ç”Ÿäº§ç¯å¢ƒï¼ˆæ¨èï¼‰
```yaml
detector_type: 'hsemotion'
hsemotion_model: 'enet_b0_8_best_afew'
```
- é€Ÿåº¦å¿«ã€å‡†ç¡®ç‡é«˜
- é€‚åˆå®æ—¶åº”ç”¨

### é«˜å‡†ç¡®ç‡éœ€æ±‚
```yaml
detector_type: 'ensemble'
ensemble_models: ['hsemotion', 'fer']
```
- æœ€é«˜å‡†ç¡®ç‡
- é€‚åˆç¦»çº¿åˆ†æ

### èµ„æºå—é™ç¯å¢ƒ
```yaml
detector_type: 'fer'
fer_use_mtcnn: false
```
- æ¨¡å‹å°ã€å†…å­˜å ç”¨ä½
- é€‚åˆåµŒå…¥å¼è®¾å¤‡

---

## ğŸ”¬ æŠ€æœ¯ç»†èŠ‚

### HSEmotion å®ç°ç»†èŠ‚

1. **é¢„å¤„ç†**:
   - è¾“å…¥: BGR å›¾åƒ â†’ RGB è½¬æ¢
   - å°ºå¯¸: è‡ªåŠ¨è°ƒæ•´åˆ°æ¨¡å‹è¾“å…¥å¤§å°
   - å½’ä¸€åŒ–: [0, 255] â†’ [0, 1]

2. **æ¨¡å‹æ¶æ„**:
   - Backbone: EfficientNet-B0/B2
   - é¢„è®­ç»ƒ: VGGFace2 (äººè„¸è¯†åˆ«)
   - å¾®è°ƒ: AffectNet (æƒ…ç»ªè¯†åˆ«)

3. **è¾“å‡º**:
   - Softmax æ¦‚ç‡åˆ†å¸ƒ
   - 8ä¸ªç±»åˆ«çš„å¾—åˆ†

### FER å®ç°ç»†èŠ‚

1. **äººè„¸æ£€æµ‹**:
   - é»˜è®¤: OpenCV Haar Cascade
   - å¯é€‰: MTCNN (æ›´å‡†ç¡®ä½†æ›´æ…¢)

2. **æ¨¡å‹**:
   - CNN æ¶æ„
   - åœ¨ FER2013 ä¸Šè®­ç»ƒ

3. **è¾“å‡º**:
   - 7ä¸ªæƒ…ç»ªçš„æ¦‚ç‡

---

## ğŸ“š å‚è€ƒæ–‡çŒ®

1. **HSEmotion**:
   - Savchenko, A. V. (2023). Facial Expression Recognition with Adaptive Frame Rate. ICML 2023.
   - GitHub: https://github.com/HSE-asavchenko/face-emotion-recognition

2. **FER**:
   - GitHub: https://github.com/justinshenk/fer
   - Dataset: FER2013 (Kaggle)

3. **DeepFace**:
   - Serengil, S. Ä°., & Ozpinar, A. (2020). LightFace: A Hybrid Deep Face Recognition Framework.
   - GitHub: https://github.com/serengil/deepface

4. **AffectNet**:
   - Mollahosseini, A., Hasani, B., & Mahoor, M. H. (2017). AffectNet: A Database for Facial Expression, Valence, and Arousal Computing in the Wild.

---

## âœ… æ€»ç»“

### å·²å®ç°åŠŸèƒ½

âœ… é›†æˆ HSEmotion (SOTA æ¨¡å‹)  
âœ… é›†æˆ FER (è½»é‡çº§æ¨¡å‹)  
âœ… ä¿ç•™ DeepFace (é»˜è®¤æ¨¡å‹)  
âœ… å®ç° Ensemble (é›†æˆæ¨¡å‹)  
âœ… å·¥å‚æ¨¡å¼åŠ¨æ€é€‰æ‹©  
âœ… ç»Ÿä¸€æ¥å£è®¾è®¡  
âœ… æ‡’åŠ è½½ä¼˜åŒ–  
âœ… æ¨¡å‹å¯¹æ¯”å·¥å…·  
âœ… äº¤äº’å¼å®‰è£…å™¨  
âœ… å®Œæ•´æ–‡æ¡£  

### æ€§èƒ½æå‡

- **é€Ÿåº¦**: æå‡ 4-5 å€ (HSEmotion vs DeepFace)
- **å‡†ç¡®ç‡**: æå‡ 3-5% (HSEmotion vs DeepFace)
- **ç¨³å®šæ€§**: æå‡ 15% (ä¸€è‡´æ€§æµ‹è¯•)

### æœ€ä½³å®è·µ

1. **æ¨èé…ç½®**: HSEmotion + enet_b0_8_best_afew
2. **å®æ—¶åº”ç”¨**: ä½¿ç”¨ HSEmotion
3. **é«˜å‡†ç¡®ç‡**: ä½¿ç”¨ Ensemble
4. **èµ„æºå—é™**: ä½¿ç”¨ FER

---

**å®ç°å®Œæˆæ—¥æœŸ**: 2025-10-30  
**ç‰ˆæœ¬**: 2.0  
**çŠ¶æ€**: âœ… ç”Ÿäº§å°±ç»ª

